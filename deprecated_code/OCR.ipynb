{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09774fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps, ImageFilter\n",
    "import pytesseract\n",
    "import re\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81b00986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_OCR(path):\n",
    "    data = {\n",
    "        'name': '',\n",
    "    }\n",
    "    img = Image.open(path)\n",
    "    og_width, og_height = img.size\n",
    "    left = 150\n",
    "    top = 150\n",
    "    right = og_width - 150\n",
    "    bottom = 1400\n",
    "    cropped = img.crop((left, top, right, bottom))\n",
    "    crop_width, crop_height = cropped.size\n",
    "    scaling_factor = 2\n",
    "    resized = cropped.resize(\n",
    "        (crop_width * scaling_factor, crop_height * scaling_factor),\n",
    "        resample= Image.LANCZOS\n",
    "        )\n",
    "    gray = ImageOps.grayscale(resized)\n",
    "    text = pytesseract.image_to_string(gray, lang='eng')\n",
    "    name_re = '^[A-Za-z ]+'\n",
    "    data['name'] = re.search(name_re, text).group(0)\n",
    "    # print(re.search(name_re, text))\n",
    "    gray.show()\n",
    "    return data\n",
    "\n",
    "def go_through_folder(filepath):\n",
    "    for file in os.listdir(filepath):\n",
    "        print(image_OCR(f'{filepath}/{file}'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ea1f2a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tiktok_screenshot(image_path, output_path=\"processed_image.png\"):\n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Resize (optional: improves OCR accuracy)\n",
    "    scale_percent = 150  # Increase size by 50%\n",
    "    width = int(gray.shape[1] * scale_percent / 100)\n",
    "    height = int(gray.shape[0] * scale_percent / 100)\n",
    "    gray = cv2.resize(gray, (width, height), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "    # Adaptive thresholding (better for mixed backgrounds)\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 15\n",
    "    )\n",
    "\n",
    "    # Optional: Morphological operations to thicken text\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Save processed image\n",
    "    cv2.imwrite(output_path, morph)\n",
    "    print(f\"Processed image saved at {output_path}\")\n",
    "\n",
    "    processed_img = Image.open('processed_image.png')\n",
    "    og_width, og_height = processed_img.size\n",
    "    left = 150\n",
    "    top = 150\n",
    "    right = og_width - 150\n",
    "    bottom = 1400\n",
    "    cropped = processed_img.crop((left, top, right, bottom))\n",
    "    text = pytesseract.image_to_string(cropped, lang='eng')\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f2f25545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image saved at processed_image.png\n",
      "Karen jal\n",
      "she/her/hers\n",
      "\n",
      "@kb_houston\n",
      "439 147 #&°&#®#647.8K\n",
      "\n",
      "Following ~~ Followers | Likes\n",
      "\n",
      "({ )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(preprocess_tiktok_screenshot('photos_sample/IMG_8339.JPG'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab44fc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 68 121 108]\n",
      "  [ 58 111  98]\n",
      "  [ 52 102  90]\n",
      "  ...\n",
      "  [242 238 233]\n",
      "  [255 254 249]\n",
      "  [255 254 246]]\n",
      "\n",
      " [[ 37  91  78]\n",
      "  [ 33  87  74]\n",
      "  [ 40  93  80]\n",
      "  ...\n",
      "  [208 204 199]\n",
      "  [242 239 234]\n",
      "  [255 255 248]]\n",
      "\n",
      " [[ 24  80  67]\n",
      "  [ 17  73  60]\n",
      "  [ 36  90  77]\n",
      "  ...\n",
      "  [166 162 157]\n",
      "  [214 210 205]\n",
      "  [246 244 236]]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m img = cv2.imread(path)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(img)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m norm_img = np.zeros((\u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m, img.size[\u001b[32m1\u001b[39m]))\n\u001b[32m      5\u001b[39m img = cv2.normalize(img, norm_img, \u001b[32m0\u001b[39m, \u001b[32m255\u001b[39m, cv2.NORM_MINMAX)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# img.show()\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "path = 'photos_sample/IMG_8339.JPG'\n",
    "img = cv2.imread(path)\n",
    "print(img)\n",
    "norm_img = np.zeros((img.size[0], img.size[1]))\n",
    "img = cv2.normalize(img, norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "# img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e196524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Karen al'}\n",
      "{'name': 'HoneyBloom Company J'}\n",
      "{'name': 'Tiny Cabin Montessori QO'}\n",
      "{'name': 'Victoria '}\n",
      "{'name': 'Brittany '}\n",
      "{'name': 'Leanne '}\n",
      "{'name': 'saf'}\n",
      "{'name': 'Mama Nurse Tina ja'}\n",
      "{'name': 'Rosa '}\n",
      "{'name': 'Dr'}\n",
      "{'name': 'brookeahlering al'}\n",
      "{'name': 'Olivia Clark jal'}\n",
      "{'name': 'Olivia '}\n",
      "{'name': 'Jessie Marie al'}\n",
      "{'name': 'Heather'}\n",
      "{'name': 'Bex '}\n",
      "{'name': 'Julia '}\n",
      "{'name': 'TraciDoula'}\n",
      "{'name': 'Helene MomJourney JO'}\n",
      "{'name': 'Rebekah '}\n",
      "{'name': 'Sacia'}\n",
      "{'name': 'Alexus '}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mgo_through_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mphotos_sample\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mgo_through_folder\u001b[39m\u001b[34m(filepath)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgo_through_folder\u001b[39m(filepath):\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os.listdir(filepath):\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[43mimage_OCR\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfilepath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mimage_OCR\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m     19\u001b[39m text = pytesseract.image_to_string(gray, lang=\u001b[33m'\u001b[39m\u001b[33meng\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     20\u001b[39m name_re = \u001b[33m'\u001b[39m\u001b[33m^[A-Za-z ]+\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m data[\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mre\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_re\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroup\u001b[49m(\u001b[32m0\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# print(re.search(name_re, text))\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# gray.show()\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "go_through_folder('photos_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f22978c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Karen al\n",
      "\n",
      "@kb_houston\n",
      "439 1,147 647.8K\n",
      "Following Followers Likes\n",
      "\n",
      "Follow Message v\n",
      "\n",
      "mostly my cat, sometimes my life\n",
      "MI\n",
      "% kbhouston32@gmail.com\n",
      "\n",
      "(=) Showcase\n",
      "\n",
      "Niy ) Tl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pytesseract.image_to_string(cropped, lang='eng'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73299407",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
